% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/string_operation.R
\name{do_tokenize}
\alias{do_tokenize}
\title{Tokenize text and unnest}
\usage{
do_tokenize(df, input, output = token, token = "words", drop = TRUE,
  with_id = TRUE, ...)
}
\arguments{
\item{df}{Data frame}

\item{input}{Set a column of which you want to split the text or tokenize.}

\item{output}{Set a column name for the new column to store the tokenized values.}

\item{token}{Select the unit of token from "characters", "words", "sentences", "lines", "paragraphs", and "regex".}

\item{drop}{Whether input column should be removed.}

\item{with_id}{Whether output should contain original document id and sentence id in each document.}

\item{to_lower}{Whether output should be lower cased.}
}
\value{
Data frame with tokenized column
}
\description{
Tokenize text and unnest
}

